{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n","# Use Watsonx to analyze customer review comments to gain insights inorder to determine improvements in product"]},{"cell_type":"markdown","metadata":{},"source":["**Note:** Please note that for the watsonx challenge, please run these notebooks in IBM Cloud and not on on your laptop/desktop."]},{"cell_type":"markdown","metadata":{},"source":["This notebook contains the steps and code to demonstrate support of text summarization in Watsonx. It introduces commands for data retrieval, model testing and scoring.\n","\n","Some familiarity with Python is helpful. This notebook uses Python 3.10."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"setup\"></a>\n","## Set up the environment"]},{"cell_type":"markdown","metadata":{},"source":["### Install and import the dependecies"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install datasets | tail -n 1\n","!pip install scikit-learn | tail -n 1\n","!pip install ibm-watson-machine-learning==1.0.349 | tail -n 1\n","!pip install rouge_score\n","!pip install evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os, getpass\n","from pandas import read_csv\n","import evaluate"]},{"cell_type":"markdown","metadata":{},"source":["### Watsonx API connection\n","This cell defines the credentials required to work with watsonx API for Foundation\n","Model inferencing.\n","\n","**Action:** Provide the IBM Cloud user API key. Instructions have been provided to generate IBM Cloud API key. For details, see\n","[documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from ibm_cloud_sdk_core import IAMTokenManager\n","from ibm_cloud_sdk_core.authenticators import IAMAuthenticator, BearerTokenAuthenticator\n","import os, getpass\n","\n","access_token = IAMTokenManager(\n","    apikey = getpass.getpass(\"Please enter your api key (hit enter): \"),\n","    url = \"https://iam.cloud.ibm.com/identity/token\"\n",").get_token()"]},{"cell_type":"markdown","metadata":{},"source":["### Defining the project id\n","The API requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. When you run notebook on IBM Cloud, project in which it runs is saved as environment variable PROJECT_ID.\n","\n","**Hint**: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be `Projects / <project name> /`. Click on the `<project name>` link. Then get the `project_id` from Project's Manage tab (Project -> Manage -> General -> Details).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["try:\n","    project_id = os.environ[\"PROJECT_ID\"]\n","except KeyError:\n","    project_id = input(\"Please enter your project_id (hit enter): \")"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"data\"></a>\n","## Train/test data loading"]},{"cell_type":"markdown","metadata":{},"source":["Load train and test datasets. At first, training dataset (`train_data`) should be used to work with the models to prepare and tune prompt. Then, test dataset (`test_data`) should be used to calculate the metrics score for selected model, defined prompts and parameters."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filename_test = 'https://watsonx-challenge-2024.s3.us.cloud-object-storage.appdomain.cloud/test.csv'\n","filename_train = 'https://watsonx-challenge-2024.s3.us.cloud-object-storage.appdomain.cloud/train.csv'\n","\n","test_data = read_csv(filename_test)\n","train_data = read_csv(filename_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"models\"></a>\n","## Foundation Models on Watsonx"]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","Below code invokes Watson Machine Learning API to invoke Watsonx.ai LLMs\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import requests\n","\n","class Prompt:\n","    def __init__(self, access_token, project_id):\n","        self.access_token = access_token\n","        self.project_id = project_id\n","\n","    def generate(self, input, model_id, parameters):\n","        wml_url = \"https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2023-05-28\"\n","        Headers = {\n","            \"Authorization\": \"Bearer \" + self.access_token,\n","            \"Content-Type\": \"application/json\",\n","            \"Accept\": \"application/json\"\n","        }\n","        data = {\n","            \"model_id\": model_id,\n","            \"input\": input,\n","            \"parameters\": parameters,\n","            \"project_id\": self.project_id\n","        }\n","        response = requests.post(wml_url, json=data, headers=Headers)\n","        if response.status_code == 200:\n","            return response.json()[\"results\"][0][\"generated_text\"]\n","        else:\n","            return response.text"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"predict\"></a>\n","## Evaluate the model, prompt and parameters"]},{"cell_type":"markdown","metadata":{},"source":["### **Analyze Product Reviews**"]},{"cell_type":"markdown","metadata":{},"source":["Define instructions for the model to summarize product reviews.\n","\n","**Note:** Please **start with using [watsonx.ai Prompt Lab](https://dataplatform.cloud.ibm.com/wx/home?context=wx)** to find better prompts that provides you the best result on a small subset training records (under `train_data` variable). Make sure to not run an inference of all of `train_data`, as it'll take a long time to get the results. To get a sample from `train_data`, you can use e.g.`train_data.head(n=10)` to get first 10 records, or `train_data.sample(n=10)` to get random 10 records. Only once you have identified the best performing prompt, update this notebook to use the prompt and compute the metrics on the test data.\n","\n","**Action:** Please edit the below cell and add your own prompt here. In the below prompt, we have the instruction (first sentence) and tags like [Document], [End] and <|assistant|> which help to organize inputs and outputs in a better way. (reference - https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models-ibm-chat.html?context=wx)\n","\n","It will act as a starting point for the participants. You will enhance it to get expected output.\n","\n","Change the prompt or add your own examples or more examples and replance it in the below cell.\n","\n","\n","**Note:** In below prompt {reviews} needs to be replaced with input product review that needs to be summarised. Rest all is part of the prompt."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["summarize_instruction = \"\"\"\n","\n","You are a retail expert. You will be given a list of product reviews. Your task is to generate a short summary, only from given product reviews from an ecommerce site to give feedback to another customer. When generating responses, prioritize correctness, i.e., ensure that your response is correct given the context and user query, and that it is grounded in the context.\n","\n","[Document]\n","{reviews}\n","[End]\n","\n","\n","<|assistant|>\n","\n","\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["### Defining the model parameters\n","We need to provide a set of model parameters that will influence the result. We will use IBM's Granite model. parameters can be updated based on prompt."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["parameters = {\n","    \"decoding_method\": \"greedy\",\"\"\n","    \"max_new_tokens\": 300,\n","    \"min_new_tokens\": 50,\n","    \"repetition_penalty\": 1\n","}\n","\n","model_id = \"ibm/granite-13b-chat-v2\""]},{"cell_type":"markdown","metadata":{},"source":["Analyze the summary of product reviews for inputs from the test set.\n","\n","**Note:** Execution of this cell could take several minutes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = []\n","prompt = Prompt(access_token, project_id)\n","product_reviews = list(test_data.reviews)\n","summary = list(test_data.summary.astype(str))\n","\n","for review in product_reviews:\n","    # Below line of code replaces {reviews} from prompt with input product review that needs to be summarised. You might need to change or replace it based on your prompt to add review.\n","    prompt_instruction = summarize_instruction.format(reviews=review)\n","    results.append(prompt.generate(prompt_instruction, model_id, parameters).replace(\"\\n\",\"\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the Rouge Scores"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load the rouge score logic for summarization evaluation\n","# To adjust this to different task other than summarization import different evalualtion metric from HF\n","rouge_scorer_hf = evaluate.load('rouge')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# test score: 50% of the words from the reference summary occur in the generated summary - should be rouge1 score should be 0.5\n","rouge_scores = rouge_scorer_hf.compute(predictions = results, \n","                        references = summary)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(rouge_scores['rouge1'])"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":1}
